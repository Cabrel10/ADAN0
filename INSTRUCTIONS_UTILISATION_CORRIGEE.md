# INSTRUCTIONS D'UTILISATION - SYSTÃˆME ADAN CORRIGÃ‰
## Guide Complet pour EntraÃ®nement, Monitoring et Reprise

**Version :** Post-corrections TensorBoard & Dashboard  
**Date :** 28 septembre 2025  
**Statut :** âœ… SYSTÃˆME ENTIÃˆREMENT OPÃ‰RATIONNEL

---

## ðŸš€ DÃ‰MARRAGE RAPIDE

### 1. EntraÃ®nement Standard (RecommandÃ©)
```bash
cd /home/morningstar/Documents/trading
timeout 30s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints
```

### 2. Monitoring en Temps RÃ©el
```bash
# Terminal 2 - Lancer le dashboard
cd /home/morningstar/Documents/trading/bot/scripts
/home/morningstar/miniconda3/envs/trading_env/bin/python training_dashboard.py

# AccÃ¨s Web : http://localhost:8050
```

### 3. Reprise d'EntraÃ®nement  
```bash
# Reprendre depuis le dernier checkpoint
timeout 30s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints \
  --resume
```

---

## ðŸ“– GUIDE DÃ‰TAILLÃ‰

### Configuration de l'Environnement

**1. Activation de l'environnement conda :**
```bash
conda activate trading_env
# Ou directement :
/home/morningstar/miniconda3/envs/trading_env/bin/python
```

**2. VÃ©rification des rÃ©pertoires :**
```bash
cd /home/morningstar/Documents/trading

# VÃ©rifier la structure
ls -la bot/config/config.yaml     # Configuration principale
ls -la bot/checkpoints/           # RÃ©pertoire des sauvegardes  
ls -la reports/tensorboard_logs/  # Logs TensorBoard
```

### Commandes d'EntraÃ®nement

**Nouveau projet :**
```bash
# Nettoyer les anciens fichiers (optionnel)
rm -rf bot/checkpoints/* reports/tensorboard_logs/*

# Lancer un nouvel entraÃ®nement
timeout 3600s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints
```

**EntraÃ®nement longue durÃ©e :**
```bash
# Pour entraÃ®nement de plusieurs heures
nohup timeout 14400s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints \
  > training_$(date +%Y%m%d_%H%M%S).log 2>&1 &

echo $! > training.pid  # Sauvegarder le PID
```

**Reprise intelligente :**
```bash
# Le systÃ¨me dÃ©tecte automatiquement le dernier checkpoint
timeout 7200s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints \
  --resume
```

---

## ðŸ“Š MONITORING & DASHBOARD

### Dashboard Web (RecommandÃ©)

**1. Lancement :**
```bash
cd bot/scripts
/home/morningstar/miniconda3/envs/trading_env/bin/python training_dashboard.py
```

**2. AccÃ¨s :**
- **URL :** http://localhost:8050  
- **Interface :** Dashboard interactif temps rÃ©el
- **DonnÃ©es :** TensorBoard + mÃ©triques personnalisÃ©es

**3. FonctionnalitÃ©s disponibles :**
- ðŸ“ˆ Graphiques de performance en temps rÃ©el
- ðŸ“Š Comparaison multi-workers  
- ðŸ“‹ MÃ©triques dÃ©taillÃ©es portfolio
- ðŸ’¾ Export des donnÃ©es

### TensorBoard Classique

**Lancement TensorBoard :**
```bash
# Si TensorBoard fonctionne dans votre environnement
tensorboard --logdir reports/tensorboard_logs --port 6006

# AccÃ¨s : http://localhost:6006
```

**Note :** En cas d'erreur TensorBoard, utilisez le dashboard personnalisÃ© qui lit les mÃªmes donnÃ©es.

### VÃ©rification des DonnÃ©es

**ContrÃ´le des fichiers gÃ©nÃ©rÃ©s :**
```bash
# VÃ©rifier les logs TensorBoard
ls -la reports/tensorboard_logs/
# Devrait contenir : events.out.tfevents.* et progress.csv

# VÃ©rifier les checkpoints
ls -la bot/checkpoints/
# Devrait contenir : checkpoint_YYYYMMDD_HHMMSS_ep*_step*/
```

**Test de lecture TensorBoard :**
```bash
/home/morningstar/miniconda3/envs/trading_env/bin/python -c "
from tensorboard.backend.event_processing.event_accumulator import EventAccumulator
import glob
tb_files = glob.glob('reports/tensorboard_logs/events.out.tfevents.*')
if tb_files:
    acc = EventAccumulator(tb_files[0])
    acc.Reload()
    print(f'Tags disponibles: {acc.Tags()[\"scalars\"]}')
    print('âœ… TensorBoard lisible')
else:
    print('âŒ Aucun fichier TensorBoard')
"
```

---

## ðŸ’¾ GESTION DES CHECKPOINTS

### Sauvegarde Automatique

**Configuration actuelle :**
- **FrÃ©quence :** Tous les 10,000 steps  
- **Maximum :** 5 checkpoints conservÃ©s
- **Sauvegarde finale :** Toujours Ã  l'arrÃªt

**Structure des checkpoints :**
```
bot/checkpoints/checkpoint_YYYYMMDD_HHMMSS_epXXXXXX_stepXXXXXXXXXX/
â”œâ”€â”€ metadata.json          # MÃ©tadonnÃ©es complÃ¨tes
â”œâ”€â”€ optimizer.pt           # Ã‰tat de l'optimiseur  
â””â”€â”€ [autres fichiers modÃ¨le]
```

### Utilisation des Checkpoints

**Lister les checkpoints disponibles :**
```bash
ls -lat bot/checkpoints/ | grep checkpoint_
```

**Reprendre automatiquement :**
```bash
# Reprend depuis le plus rÃ©cent automatiquement
python bot/scripts/train_parallel_agents.py --resume [autres options]
```

**Informations d'un checkpoint :**
```bash
# Voir les mÃ©tadonnÃ©es
cat bot/checkpoints/checkpoint_*/metadata.json | jq .
```

---

## ðŸ”§ CONFIGURATION AVANCÃ‰E

### Personnalisation config.yaml

**ParamÃ¨tres d'entraÃ®nement :**
```yaml
training:
  total_timesteps: 1000000        # Nombre total d'Ã©tapes
  checkpointing:
    enabled: true
    save_freq: 10000             # FrÃ©quence sauvegarde
    save_path: ${paths.trained_models_dir}
```

**ParamÃ¨tres de monitoring :**
```yaml
agent:
  checkpoint_freq: 10000          # FrÃ©quence checkpoints
  logging_level: ERROR            # Niveau de logs console
```

### Variables d'Environnement

**Optimisation performance :**
```bash
export CUDA_VISIBLE_DEVICES=0    # GPU spÃ©cifique
export OMP_NUM_THREADS=4         # Threads CPU
export MKL_NUM_THREADS=4         # Intel MKL threads
```

---

## ðŸ› DÃ‰PANNAGE

### ProblÃ¨mes Courants

**1. "Aucun fichier TensorBoard crÃ©Ã©"**
```bash
# VÃ©rifier les permissions
ls -la reports/
mkdir -p reports/tensorboard_logs
chmod 755 reports/tensorboard_logs
```

**2. "Dashboard affiche Ã©cran noir"**
```bash
# VÃ©rifier que l'entraÃ®nement a gÃ©nÃ©rÃ© des donnÃ©es
ls -la reports/tensorboard_logs/events.out.tfevents.*

# Relancer le dashboard
cd bot/scripts
python training_dashboard.py
```

**3. "Checkpoint non trouvÃ© pour resume"**
```bash
# VÃ©rifier les checkpoints existants  
ls -la bot/checkpoints/checkpoint_*/

# Lancer sans --resume pour nouveau dÃ©marrage
python bot/scripts/train_parallel_agents.py --config bot/config/config.yaml
```

**4. "Erreur de mÃ©moire"**
```bash
# RÃ©duire le nombre de workers
python bot/scripts/train_parallel_agents.py --workers 2 [autres options]
```

### Logs de DÃ©bogage

**VÃ©rifier les logs d'entraÃ®nement :**
```bash
# Si lancÃ© avec nohup
tail -f training_*.log

# En temps rÃ©el
python bot/scripts/train_parallel_agents.py [options] 2>&1 | tee debug.log
```

**Tester les composants individuellement :**
```bash
# Test rapide de validation
python test_tensorboard_checkpoint_validation.py
```

---

## ðŸ“‹ BONNES PRATIQUES

### Workflow RecommandÃ©

**1. PrÃ©paration :**
```bash
# Nettoyer si nÃ©cessaire
rm -rf bot/checkpoints/* reports/tensorboard_logs/*

# VÃ©rifier la configuration  
cat bot/config/config.yaml | grep -A5 training
```

**2. Lancement :**
```bash
# Terminal 1 : EntraÃ®nement
timeout 7200s python bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml --checkpoint-dir bot/checkpoints

# Terminal 2 : Monitoring
cd bot/scripts && python training_dashboard.py
```

**3. Surveillance :**
- Dashboard : http://localhost:8050
- VÃ©rifier checkpoints toutes les heures
- Surveiller l'utilisation disque

**4. Reprise aprÃ¨s interruption :**
```bash
# Reprendre automatiquement
python bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml --checkpoint-dir bot/checkpoints --resume
```

### Maintenance

**Nettoyage pÃ©riodique :**
```bash
# Archiver anciens logs (garder les 10 derniers)
cd reports/tensorboard_logs
ls -t events.out.tfevents.* | tail -n +11 | xargs rm -f

# Nettoyer anciens checkpoints (garder les 3 derniers)
cd bot/checkpoints  
ls -t -d checkpoint_* | tail -n +4 | xargs rm -rf
```

**Sauvegarde critique :**
```bash
# Sauvegarder les meilleurs checkpoints
cp -r bot/checkpoints/checkpoint_BEST_* ~/backup/
```

---

## âœ… VALIDATION DU SYSTÃˆME

### Test Complet AutomatisÃ©
```bash
# Valider toutes les fonctionnalitÃ©s
python test_tensorboard_checkpoint_validation.py

# Doit afficher : "ðŸŽ‰ SUCCÃˆS: Les corrections principales fonctionnent!"
```

### VÃ©rification Manuelle Rapide
```bash
# 1. Lancer entraÃ®nement court
timeout 60s python bot/scripts/train_parallel_agents.py \
  --config bot/config/config.yaml --checkpoint-dir bot/checkpoints

# 2. VÃ©rifier fichiers gÃ©nÃ©rÃ©s
ls reports/tensorboard_logs/events.out.tfevents.* && echo "âœ… TensorBoard OK"
ls bot/checkpoints/checkpoint_* && echo "âœ… Checkpoints OK"

# 3. Tester dashboard
cd bot/scripts && timeout 10s python training_dashboard.py && echo "âœ… Dashboard OK"
```

---

## ðŸŽ¯ RÃ‰SUMÃ‰ DES COMMANDES ESSENTIELLES

```bash
# ENTRAÃŽNEMENT STANDARD
timeout 30s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints

# DASHBOARD  
cd bot/scripts && /home/morningstar/miniconda3/envs/trading_env/bin/python \
  training_dashboard.py

# REPRISE
timeout 30s /home/morningstar/miniconda3/envs/trading_env/bin/python \
  bot/scripts/train_parallel_agents.py --config bot/config/config.yaml \
  --checkpoint-dir bot/checkpoints --resume

# VALIDATION
python test_tensorboard_checkpoint_validation.py
```

**ðŸŽ‰ Le systÃ¨me est maintenant entiÃ¨rement opÃ©rationnel et prÃªt pour une utilisation en production !**