#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de test pour valider les corrections implÃ©mentÃ©es dans le bot de trading.

Ce script teste :
1. Ã‰limination de la duplication des logs
2. Correction des erreurs d'ouverture de positions
3. Correction des incohÃ©rences dans les mÃ©triques
4. Correction de la terminaison prÃ©maturÃ©e
"""

import subprocess
import sys
import time
import re
import logging
from pathlib import Path

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_training_test(timeout=30):
    """Lance l'entraÃ®nement avec un timeout et capture les logs."""
    cmd = [
        "timeout", f"{timeout}s",
        "/home/morningstar/miniconda3/envs/trading_env/bin/python",
        "bot/scripts/train_parallel_agents.py",
        "--config", "bot/config/config.yaml",
        "--checkpoint-dir", "bot/checkpoints"
    ]

    try:
        logger.info(f"ðŸš€ Lancement du test d'entraÃ®nement avec timeout {timeout}s")
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd="/home/morningstar/Documents/trading"
        )

        return result.stdout, result.stderr, result.returncode
    except Exception as e:
        logger.error(f"Erreur lors de l'exÃ©cution: {e}")
        return "", str(e), 1

def analyze_logs(stdout, stderr):
    """Analyse les logs pour valider les corrections."""
    all_logs = stdout + stderr
    lines = all_logs.split('\n')

    results = {
        'duplicate_logs': False,
        'position_errors': False,
        'metrics_inconsistencies': False,
        'premature_termination': False,
        'worker_comparison': False
    }

    # Compteurs pour dÃ©tecter les doublons
    log_patterns = {
        '[RISK]': [],
        '[METRICS DEBUG]': [],
        '[POSITION_OPEN]': [],
        '[DBE_DECISION]': [],
        '[DATA_LOADER]': []
    }

    position_errors = []
    termination_messages = []
    metrics_debug = []

    logger.info("ðŸ” Analyse des logs...")

    for i, line in enumerate(lines):
        # 1. DÃ©tecter les duplications de logs
        for pattern in log_patterns:
            if pattern in line:
                log_patterns[pattern].append((i, line))

        # 2. DÃ©tecter les erreurs d'ouverture de positions
        if '[ERREUR] Impossible d\'ouvrir une position' in line:
            position_errors.append((i, line))

        # 3. DÃ©tecter les messages de terminaison
        if '[TERMINATION]' in line:
            termination_messages.append((i, line))

        # 4. Capturer les mÃ©triques debug pour vÃ©rifier la cohÃ©rence
        if '[METRICS DEBUG]' in line:
            metrics_debug.append((i, line))

    # Analyse des doublons
    logger.info("ðŸ“Š Analyse des duplications de logs:")
    for pattern, occurrences in log_patterns.items():
        if len(occurrences) > 1:
            # Grouper par timestamp approximatif (mÃªme seconde)
            timestamps = {}
            for line_num, log_line in occurrences:
                # Extraire le timestamp (approximatif)
                time_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', log_line)
                if time_match:
                    timestamp = time_match.group(1)
                    if timestamp not in timestamps:
                        timestamps[timestamp] = []
                    timestamps[timestamp].append(log_line)

            # DÃ©tecter les doublons (mÃªme timestamp, mÃªme contenu)
            for timestamp, logs in timestamps.items():
                if len(logs) > 1:
                    # VÃ©rifier si c'est vraiment un doublon (mÃªme contenu)
                    unique_logs = set(logs)
                    if len(unique_logs) < len(logs):
                        logger.warning(f"   âŒ Doublon dÃ©tectÃ© pour {pattern} Ã  {timestamp}: {len(logs)} occurrences")
                        results['duplicate_logs'] = True
                    else:
                        logger.info(f"   âœ… {pattern}: {len(logs)} occurrences distinctes Ã  {timestamp}")
                else:
                    logger.info(f"   âœ… {pattern}: 1 occurrence Ã  {timestamp}")
        elif len(occurrences) == 1:
            logger.info(f"   âœ… {pattern}: 1 occurrence unique")
        else:
            logger.info(f"   â„¹ï¸  {pattern}: aucune occurrence")

    # Analyse des erreurs de positions
    logger.info("ðŸ¦ Analyse des erreurs de positions:")
    if position_errors:
        logger.warning(f"   âŒ {len(position_errors)} erreurs d'ouverture dÃ©tectÃ©es:")
        for line_num, error in position_errors[:3]:  # Afficher les 3 premiÃ¨res
            logger.warning(f"      Ligne {line_num}: {error.strip()}")
        results['position_errors'] = True
    else:
        logger.info("   âœ… Aucune erreur d'ouverture de position dÃ©tectÃ©e")

    # Analyse des terminaisons
    logger.info("ðŸ”š Analyse des terminaisons:")
    if termination_messages:
        for line_num, msg in termination_messages:
            logger.info(f"   Ligne {line_num}: {msg.strip()}")
            if "Min steps not reached" in msg:
                results['premature_termination'] = True
                logger.warning("   âŒ Terminaison prÃ©maturÃ©e dÃ©tectÃ©e (Min steps not reached)")
            elif "Frequency check interval reached" in msg:
                logger.info("   âœ… Terminaison normale (Frequency check interval)")
            elif "Max steps reached" in msg:
                logger.info("   âœ… Terminaison normale (Max steps)")
    else:
        logger.info("   â„¹ï¸  Aucun message de terminaison trouvÃ©")

    # Analyse des mÃ©triques
    logger.info("ðŸ“ˆ Analyse des mÃ©triques:")
    if metrics_debug:
        logger.info(f"   âœ… {len(metrics_debug)} messages de mÃ©triques trouvÃ©s")
        # Afficher quelques exemples
        for line_num, metric in metrics_debug[:2]:
            logger.info(f"      Ligne {line_num}: {metric.strip()}")
    else:
        logger.warning("   âŒ Aucune mÃ©trique debug trouvÃ©e")
        results['metrics_inconsistencies'] = True

    # Chercher les comparaisons de workers
    worker_comparison_found = any('[WORKER COMPARISON]' in line or '[COMPARISON Worker' in line for line in lines)
    if worker_comparison_found:
        logger.info("   âœ… Comparaison des workers trouvÃ©e")
        results['worker_comparison'] = True
    else:
        logger.info("   â„¹ï¸  Comparaison des workers non trouvÃ©e (normal si timeout court)")

    return results

def print_test_summary(results):
    """Affiche un rÃ©sumÃ© des tests."""
    logger.info("=" * 60)
    logger.info("ðŸ“‹ RÃ‰SUMÃ‰ DES TESTS DE CORRECTIONS")
    logger.info("=" * 60)

    total_tests = len(results)
    passed_tests = sum(1 for v in results.values() if not v)  # False = test passÃ©

    test_descriptions = {
        'duplicate_logs': '1. Ã‰limination des duplications de logs',
        'position_errors': '2. Correction des erreurs d\'ouverture de positions',
        'metrics_inconsistencies': '3. Correction des incohÃ©rences de mÃ©triques',
        'premature_termination': '4. Correction de la terminaison prÃ©maturÃ©e',
        'worker_comparison': '5. Comparaison des workers'
    }

    for test_key, description in test_descriptions.items():
        status = "âŒ Ã‰CHEC" if results[test_key] else "âœ… SUCCÃˆS"
        logger.info(f"{description}: {status}")

    logger.info("=" * 60)
    logger.info(f"ðŸ“Š RÃ‰SULTAT GLOBAL: {passed_tests}/{total_tests} tests rÃ©ussis")

    if passed_tests == total_tests:
        logger.info("ðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S!")
        return True
    else:
        logger.warning("âš ï¸  CERTAINS TESTS ONT Ã‰CHOUÃ‰")
        return False

def main():
    """Fonction principale du script de test."""
    logger.info("ðŸ§ª SCRIPT DE TEST DES CORRECTIONS")
    logger.info("=" * 60)

    # VÃ©rifier que nous sommes dans le bon rÃ©pertoire
    if not Path("bot/scripts/train_parallel_agents.py").exists():
        logger.error("âŒ Script d'entraÃ®nement introuvable. VÃ©rifiez le rÃ©pertoire de travail.")
        sys.exit(1)

    # Lancer le test d'entraÃ®nement
    stdout, stderr, returncode = run_training_test(timeout=30)

    if returncode != 124:  # 124 = timeout command successful timeout
        logger.warning(f"âš ï¸  Code de retour inattendu: {returncode}")

    if not stdout and not stderr:
        logger.error("âŒ Aucune sortie capturÃ©e. VÃ©rifiez la configuration.")
        sys.exit(1)

    # Analyser les logs
    results = analyze_logs(stdout, stderr)

    # Afficher le rÃ©sumÃ©
    success = print_test_summary(results)

    # Sauvegarder les logs pour analyse manuelle si nÃ©cessaire
    log_file = Path("test_corrections_logs_output.txt")
    with open(log_file, 'w') as f:
        f.write("=== STDOUT ===\n")
        f.write(stdout)
        f.write("\n\n=== STDERR ===\n")
        f.write(stderr)

    logger.info(f"ðŸ“ Logs complets sauvegardÃ©s dans: {log_file}")

    if success:
        logger.info("ðŸŽ¯ Test terminÃ© avec succÃ¨s!")
        sys.exit(0)
    else:
        logger.error("ðŸ’¥ Test terminÃ© avec des erreurs!")
        sys.exit(1)

if __name__ == "__main__":
    main()
