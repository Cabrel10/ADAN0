# Model architecture and diagnostics configuration
# Generated by configuration migration on 2025-08-22T08:08:09.512171

model:
  architecture:
    attention:
      dropout: 0.1
      num_heads: 4
      use_residual: true
    block_a:
      dropout: 0.1
      kernel_size: 3
      leaky_relu_negative_slope: 0.01
      out_channels: 64
      padding: 1
    block_b:
      dropout: 0.2
      multi_scale:
      - dilation: 1
        kernel_size: 3
        padding: 1
      - dilation: 1
        kernel_size: 5
        padding: 2
      - dilation: 2
        kernel_size: 3
        padding: 2
      se_ratio: 16
    head:
      activation: leaky_relu
      dropout: 0.3
      hidden_units:
      - 256
      - 128
  diagnostics:
    attention_map_dir: ${paths.models_dir}/attention_maps
    background: '#FFFFFF'
    bollinger_band: '#85C1E9'
    bollinger_mid: '#2980B9'
    grid: '#ECF0F1'
    histogram_down: '#E74C3C'
    histogram_up: '#2ECC71'
    ma_long: '#8E44AD'
    ma_medium: '#3498DB'
    ma_short: '#F1C40F'
    macd_line: '#2E86C1'
    rsi_line: '#34495E'
    rsi_overbought: '#E67E22'
    rsi_oversold: '#2ECC71'
    save_attention_maps: true
    signal_line: '#F39C12'
    target_layer: block_b.conv3
    use_grad_cam: true
    use_integrated_gradients: true
    volume_down: '#BDC3C7'
    volume_up: '#95A5A6'
  style:
    axes_facecolor: white
    bottom_margin: 0.1
    candle_width: 0.8
    figure_facecolor: white
    font_family: sans-serif
    font_size: 10
    grid_alpha: 0.3
    hspace: 0.2
    left_margin: 0.05
    legend_edgecolor: '#DDDDDD'
    legend_facecolor: white
    legend_frameon: true
    legend_loc: upper left
    line_width: 1.0
    right_margin: 0.95
    top_margin: 0.95
    volume_alpha: 0.3
